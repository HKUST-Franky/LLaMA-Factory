AIP推理

bash /root/LLaMA-Factory/api.sh


其中关于API推理重点介绍：

由于AutoDL镜像没有公网IP，所以通常不能直接从外部访问。但AutoDL提供了6006这个特殊端口作为对外通道。
利用这点，我们可以把模型API也设置在6006端口。这样一来，模型就可以在云端部署，并允许从任何地方远程访问。
只要知道API地址，无论在哪里，都能连接并使用云端部署的模型。
（这个的具体使用介绍可以前往哔哩哔哩：自负的魔方 账号观看，以便清楚理解使用方法）

为此，你可以通过一个简单的API代码和模型交互：

import openai
import sys

api_key = "EMPTY"
openai.api_base = "你的AUtodl自定义服务里面的网址/v1"


def chat_with_gpt3_5(messages):
    response = openai.ChatCompletion.create(
        model="xxx",
        messages=messages,
        api_key=api_key,
        stream=True  # 启用流式输出
    )

    full_response = ""
    for chunk in response:
        if 'choices' in chunk and len(chunk['choices']) > 0:
            content = chunk['choices'][0].get('delta', {}).get('content', '')
            if content:
                print(content, end='', flush=True)
                full_response += content
    print() 
    return full_response

conversation = [
    {"role": "system", "content": "你是一个聪明的AI"}
]

while True:

    user_input = input("You: ")

    if user_input.lower() == '退出':
        print("Assistant: 再见！")
        break

    conversation.append({"role": "user", "content": user_input})

    print("Assistant: ", end='', flush=True)
    assistant_message = chat_with_gpt3_5(conversation)

    conversation.append({"role": "assistant", "content": assistant_message})


