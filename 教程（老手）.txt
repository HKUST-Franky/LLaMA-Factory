
建议您先完成新手教程，然后再尝试高级教程。如果您已经熟悉基础操作，
可以探索此系统的更多功能。这里，为您简要介绍一些实用的工具。

------------------------------------------------------------------------------------------------------------------------------------------------------
《工具一：数据集创造功能》

如果您觉得手动制作数据集过于繁琐，无需担心。无论是小说、
新闻、手册还是其他类型的文章，只需将文本复制到这个位置：
LLaMA-Factory/数据集全自动处理/受刑文本.txt

然后运行以下命令：bash /root/LLaMA-Factory/chuli/半自动.sh

接下来等待数据集制作完成。这个过程可以自动将您的原始文件转换成可训练的问答数据集，
您可以直接在Web端使用这个名为“创造数据集”的数据集。（我在里面放了一段从我公众号里面的文章，你可以删除替换为你自己想要处理的内容）

------------------------------------------------------------------------------------------------------------------------------------------------------
《工具二：数据集扩充功能》
如果你的数据集特别少，甚至只有短短的十几条。那么这是非常不建议训练的，第一是及其容易过拟合。第二是训练的效果也不会很好。
但是又没法再收集更多的数据了，这种情况下，我建议使用本镜像的“数据集扩充功能”

这个功能可以把少量的数据集通过模型的转述扩大好几倍。例如你只有10条问答对，可以扩充到100条。100条问答对，可以扩充到1000条。
当然，太多也不好，建议扩充4、5倍就行了。

这里的原理实际上就是让模型，例如（chatgpt）用不同的语气或者说话方式，重述一遍你问答对里面的“答”的部分，用不同的表达方法转述。但核心内容意思
还是那个意思。只不过表达方式变了而已。这种方法也叫作数据增强，在数据集很少的情况下是一个不错的一个技巧。

那么我将向您介绍如何使用这个功能：
首先找到这个路径：LLaMA-Factory/数据集全自动处理/数据增强

然后打开：数据扩充.txt  
在这里放入你需要扩充的问答对。

例如：

问：上火吃什么东西比较消火？
答：可以吃些良性水果，比如梨、西瓜，也可以喝一些凉茶苦瓜等等。

问：哪些食物比较容易上火？
答：一般来说这些食物普遍容易上火：辣椒、炸鸡、油条、烧烤、榴莲、坚果瓜子等等。


将问答对粘贴到：数据扩充.txt  文件里面，然后保存。（我在里面放了一些示例，你可以直接删除）

接着运行这个指令：

bash /root/LLaMA-Factory/chuli/数据增强/数据扩充.sh

脚本首先会确认你需要扩充几倍。例如你有10条问答对。输入4，就是4倍，也就是会扩充40条。输入5，就是5倍。也就是会扩充50条。
输入好之后，按回车就会自动开始扩充。扩充完毕后，会将你的原数据，以及扩充好的数据。一起打包制作成可训练的数据格式，名字叫做“扩充数据集” 


-----------------------------------------------------------------------------------------------------------------------------------------------------

《工具三：模型切换功能》

此系统默认使用internlm2_5-7b-chat模型，但您可以根据喜好更换其他模型。请运行以下命令：
python /root/LLaMA-Factory/模型贩卖机.py

执行后，系统会提示您输入模型的名称。请从以下支持的模型列表中选择所需模型名称（该列表将持续更新）。复制并粘贴所选模型名称到终端，然后按回车键开始下载过程。下载的模型将自动保存在autodl-tmp目录中。请确保此目录至少有30GB的可用空间。如果存储空间不足，系统将自动清空所有数据！


《Qwen系列模型》                      《Chatglm系列模型》                  《llama系列模型》                  《书生》                        《视觉语言模型》               《杂七杂八模型》

Qwen2.5-7B-Instruct                   glm-4-9b                           llama3.1-8B-chat                  internlm2_5-7b-chat            Qwen2-VL-7B-Instruct         Gemma-2-9B-Chat

Qwen2.5-14B-Instruct                  glm-4-9b-chat                      Llama3-8B-chat

Qwen2-0.5B                            glm-4-9b-chat-1m

Qwen2-7B-Chat                         

Qwen2-72B-chat

Qwen1.5-1.8B-Chat

Qwen1.5-7B-Chat

Qwen1.5-14B-Chat

Qwen1.5-32B-Chat

Qwen-7B-Chat

Qwen-14B-Chat

Qwen2-72B-chat





