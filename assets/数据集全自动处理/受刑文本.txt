如何训练好一个LLM大语言模型？

目前，深度学习的影响非常广泛。AI绘画、AI声音克隆、AI大语言模型等等等等。市面上很多资料文章和视频都非常多。以至于让新手甚至在几个小时就可以掌握。

但是，再往上呢？在学习深度学习的这个领域。从0到1并不难。只需要会部署项目，能跑通模型就算入门了。但是想要从1跨越到2。甚至更高。所需要花费的心血可就是另一个层次了。其中更多的是那种捉摸不透的经验主义以及大大小小的信息差。

就好比想要训练一个公司的AI客服。看了网上很多的教学文章，不想用RAG和外部知识库等等的功能来搭建。而是想要用大模型训练来训练微调。在成功跑通模型后，开始了第一次的训练。结果发现，甚至还不如没训练过的模型要好！

这就是生成式模型的一个巨大的壁垒。也是困扰很多研究人员的灾难性遗忘。不仅仅是这个，还要面对模型出现的幻觉现象。身份认知问题。逻辑能力差、过拟合、欠拟合、经常重复同一句话、自我矛盾....... 实在太多了。

大语言模型的训练，可能是相对于AI绘画、声音克隆、唱歌等等。最难以出好效果的深度学习项目了。这不仅仅是取决于模型和架构的问题。更多的是来自于数据和训练资源的问题。

目前，无论是社区，还是需要付费的知识平台。很少有人会专门讲如何训练好一个大语言模型。更多的还是在讲如何把模型跑通。又或者说一个大概的训练思路和方向。以及架构和各种训练的原理描述。要不就是完全看不懂，看了好像和没看一样。更可气的是，一些付费的知识文章中，在个人介绍中洋洋洒洒的列举各种头衔、比赛名次、实习经验。本以为其文章会是高质量的内容分享。但付款打开后却还是一些模型部署、代码讲解。甚至还不如很多免费的教学帖！真是气人！

所以，这也是我为什么要写这篇文章的初衷。不过我在这里还是要给大家泼一盆冷水。就是个人而言。你是绝对训练不出一个完美拟合的模型的。为什么呢？因为即便强如chatglm3-6b 由清华大学耗费好几个月的精力训练，模型还是存在很明显的过拟合现象。也就是说，即便是开源的主流模型。也没法达到完美的拟合状态。甚至还会过拟合。所以更别说我们个人用户了。我个人认为当前开源模型里拟合状态最好的就是llama3系列，以及glm4和qwen2系列的模型。

我本人是在微调这条路上走过无数的坑，以及消耗了很多很多的金钱。如果单论训练模型的次数，可能至少也有3000多次了。所以我十分明白到底什么是有效果的，什么是没效果的。

接下来，我将要讲的是，为什么你用你做的语料训练模型。模型的效果这么差。我会先说几种常见的现象。

第一种：过拟合

这是最常见的问题了。基本上第一次微调可能都会经历模型的问题。那所谓的过拟合又是什么意思呢？简单来说就是模型对于数据集里的内容过于的敏感了。有的时候甚至会出现说出和数据集里面一模一样的语句。可以理解为"学傻了"。

图片

这时候你要是问它没有学过的内容，它很可能会直接开始乱讲话。说一些毫无逻辑，狗屁不通的东西。或者一直重复输出一个句子或单词。

其实用一个比喻就很好理解了。小明是一个很聪明的学生，什么都懂一点。有一天，他的父母想让他学一个新的东西——话剧表演。父母给了小明一本话剧书让他学习里面人物的说话风格。他们让小明看了好几十遍这本书。学到后面小明已经达到了倒背如流的程度。父母认为小明已经学成了。

父母：“你学的怎么样呀？”

小明："哦，我亲爱的妈妈。我已经学的非常优秀秀秀秀秀秀秀秀秀秀....." 

父母傻了：还记得我们是谁吗？

小明："你是,你是我亲爱的父母!不,等等,是观众?还是我自己?(困惑地环顾四周)我是哈姆雷特?不,我是朱丽叶?等等,或许我是狗?(突然开始模仿狗叫)"

父母慌了：“宝贝别闹了，还记得你最擅长的口算吗？374×29+486÷3等于多少？”

小明："哦~根据薛定谔的猫理论,答案既是对的也是错的！374乘29加486除3等于...等于...等于0101010101....(突然开始念二进制)"

这个例子里面。小明就是大模型。给小明学习的话剧书就是数据集。父母和小明对话就是在测试。

其中：

第一轮对话，指代的是无意义的重复。

第二轮对话，指代的是身份和逻辑混乱。

第三轮对话，指代的是失去原有能力灾难性遗忘、幻觉现象。

那如何让小明不要变成这样呢？很简单——让小明不要读那么多遍的书。以及同时让他学些别点的内容，不要只关注那一本话剧书。或者直接抛弃小明，换一个更聪明的大明。翻译一下就是：减少训练时的epoch。还有训练的时候，将你的数据集和通用数据集一起训练。以及可以换一个参数更大更聪明的模型。

希望这个例子可以让你明白过拟合以及解决思路。

第二种：欠拟合

这和过拟合刚好是一个反面。过拟合是训练的epoch（轮数）过多，loss过低，导致模型对训练集过于敏感了。而欠拟合是训练的过于少了，loss过高。模型根本就没有拟合好，没有学会。对数据集里的东西半懂不懂的状态。属于学的既不好，且整体能力还下降了。包括逻辑混乱。以及输出过于简单，缺乏相关性。所以欠拟合甚至还不如过拟合，至少过拟合还算是学到了东西。而欠拟合是既没有学到什么东西，原本的能力还下降了。所以宁可过拟合也不要欠拟合。

这个也很好解决，多训练几轮，或者拉高学习率让模型强行拟合，让loss降下去。

第三种：模型参数太小

这个就是一个选择问题，大家都知道模型的参数越大，训练的效果当然就会越好。但对于个人用户而言9b可能就是家用级显卡的极限了。但如果不是个人用户的话，建议使用llama3-70b或者qwen2-70等等更高参数的模型进行训练。相对于小参数模型，在同一套数据集下，会有明显的提升。

第四种：数据集太差

如果你给模型训练的资料很差，那模型最终训练出来的效果也肯定很差。不要抱有侥幸心理。认为随随便便制作的数据集会训练出高质量的模型。我可以很负责任的和大家说，模型的最终质量有80%都来源于数据集。你后续的调参、改变数据架构、更换模型，最多也只能提升20%的水平。所以，真正决定你模型的质量，完完全全就是你的数据集！这非常非常非常的重要！千万不要随便应付。且数据集宁可质量高，数量少，也不要质量一般，数量多。

那么，什么才算质量好的数据集呢？我个人的经验是如下：

1.不要有一模一样的内容。

2.保证统一性，和多样性

3.数据集里面的每一段都要保证有逻辑性。不要出现冲突的内容

4.可以的话，尽可能选择多轮对话数据集



我现在来逐一解释，首先关于：

1.不要有一模一样的内容。

——因为会过拟合。虽然我说过拟合不可避免，但是过拟合也有严重和轻微之分。我们需要做到的就是尽可能轻微过拟合。所以，如果有一模一样的数据，就很容易出现模型过度学习这些重复样本。导致在重复的内容上学习的过多。忽略了别的数据。

2.保证统一性，和多样性

统一性意味着数据集里面的内容最好都是一致的，例如风格、语气、格式、情绪、答案一致。

多样性则是确保数据集包含了各种领域的内容，不限于日常、经济、政治、各种学科、话题。这方面的多样性。

为什么要追求统一性？以学习绘画为例：假设你热衷于二次元角色描绘。通过不断研究心仪的画作并向各位艺术家学习相关技巧，你的风格将逐渐与所学对象一致。这种过程中，有明确的学习对象和标准，这就是统一性的一种体现。统一性的提升使学习模型更容易掌握技能，而且能够显著提高学习效果，使模型更清晰地理解你的学习目标。

那么，为什么又需要保持多样性呢？还是用之前例子说明：当你精通了二次元角色的绘制之后，你可能只擅长画二次元。如果有人请求你绘制一幅传统的毛笔山水画，结果可能会非常糟糕。这就是多样性的不足。解决方案是学习毛笔山水画和其他不同风格的绘画，以此来弥补不足并不断增强多样性。

实际上，这两者其实是挺冲突的。如果想让模型某一个方面训练的很好，那统一性实际上是越确定越好。但这样的话，多样性反而就消失了。如果想要模型拥有多样性。那必然统一性就会变差，因为要学的东西各种各样。

所以，这里需要做取舍。如果你最终的目标是想要训练出一个垂直模型或者AI客服的话。例如法律模型或者耳机AI客服。只需要准备好用户可能会聊到的内容。针对这些内容给出相关的回复。从而保证在固定领域的统一性。

如果你又想要统一性和多样性，那就要做出取舍，平衡好这两者的数据。这里还是看你的实际目标是什么了。



3.数据集里面的每一段都要保证有逻辑性。不要出现冲突的内容

这个其实很好理解，如果你的数据里面前面说1+1=2 但后面又说1+1=3 那模型就会搞不懂你到底是什么意思。从而迟迟无法学会你给的内容，导致最终效果很差，导致幻觉现象加重和乱讲话。



4. 可以的话，尽可能选择多轮对话数据集

为什么可以的话，尽可能选择多轮对话数据集？如果你最终测试的时候，只打算每次都只交互一次，如果是这种形式的话，用单轮的数据集当然没什么问题。但是大部分时候，我们交流的时候，肯定不会只说一轮就结束了。那如果再想要和模型继续交流，例如交流第2轮、第3轮、第4、5、6、7.....轮。你会发现，聊的越多，模型变得越傻。远远不如开始的回答效果好。这其实很正常。因为你的数据集如果是单轮的话，那效果最好的肯定就是单轮的交互。虽然预训练模型本身有多轮对话的能力。但如果你想要效果更好，那多轮对话肯定是要比单轮效果好的。

优点：

(1) 上下文理解能力的增强：多轮对话数据使得模型能够学习如何在一系列相关的交流中理解和保持上下文信息。这种能力是单轮对话所无法提供的，因为单轮对话通常只涉及一个来回的交互，缺乏长期的上下文依赖。

(2) 对话的连贯性和逻辑的提升：在多轮对话中，模型需要学习如何维持话题的连续性并适当地转换话题，这有助于提高对话的自然流畅性和逻辑性。模型训练在这种环境下能够更好地模拟真实人类间的交流模式。

(3) 改善对复杂问题的处理能力：在多轮对话中，某些问题或主题可能需要通过多个步骤逐步探讨和解决。这种类型的数据训练帮助模型学习如何有效地处理需要多步推理的复杂问题。

这就是为什么多轮对话数据集的好处。



我这里可以给大家展示一下什么是质量好，和质量差的数据集。假设我们想要训练出一个关于耳机的AI客服。这是我们的问题：为什么我的耳机感觉有些接触不良？



低质量：可以检查一下耳机插头，或者看看是否耳机孔堵住了。

（为什么质量低？首先很短，然后内容很简单，且没有提供详细的诊断步骤或解释可能导致问题的具体原因。对问题的分析不足）

高质量：首先，请你先检查一下耳机插头和设备的接口是否有灰尘或污渍？这些杂质可能阻碍信号传输。可以使用干净的微纤维布轻轻擦拭接口。然后，检查一下耳机线有没有损伤或折断的迹象，线材损伤也常常是导致接触不良的原因。如果耳机是折叠式的，检查折叠部分的线材是否因多次弯曲而内部断裂。最后，如果耳机是无线的，请确保蓝牙连接稳定，且耳机电池充足。如果这些步骤仍未解决问题，且耳机在质保期，可以申请换货，我们将为您提供更换服务！

（为什么质量高？因为内容长，所以模型学到的东西就多。回答的角度多方面。对问题的分析更全面。从而加强模型对相似问题的学习能力）

既然回答的部分有质量的高低，那问的地方有没有呢？当然有！问答对，问也是有"好问"和“差问”之分的。还是用耳机举例，首先这是一个回答：

蓝牙耳机音频延迟通常与耳机和设备之间的连接协议有关。如果您经历了显著的音频延迟，首先请检查耳机和音频源设备是否都支持低延迟蓝牙技术，如aptX Low Latency或AAC，这些技术能显著减少蓝牙传输的延迟。其次，更新您的设备和耳机到最新的软件版本，这可以解决已知的延迟问题。如果问题依旧，尝试重新配对耳机和设备，有时候重新建立连接可以减少延迟。最后，如果您在特定应用程序中经历延迟，尝试检查应用的音频设置或更新该应用，以确保它是优化过的。

低质量问题：蓝牙耳机声音为什么跟不上视频？

（为什么质量低？缺乏具体的信息。询问的内容不明确。没有详细的过程。内容短。）

高质量问题：我最近购买的蓝牙耳机在观看视频时音频总是有延迟，特别是在使用某些应用时更为明显。我该如何减少这种延迟？请问有哪些具体的步骤可以尝试解决这个问题？

（为什么质量高？很具体、非常明确的询问、由一个主问题细分出多个细化问题。内容长。）



下面我们来讲讲实际的测试环节吧，我可不想只谈理论。首先，我的的视频链接：

https://www.bilibili.com/video/BV1Yx4y167qs/?spm_id_from=333.999.0.0&vd_source=dc0e5f82ef841663cb2763adcb8f5ba9

里面讲过了关于基本的模型训练方法。但是关于训练内容的还是讲的很浅显。所以我在这里讲一下关于更详细的一些内容。关注我的公众号：AI会思考    发送：数据集   会给你发送一个通用的数据集。（是的，这就是广告）

这里我拿垂直模型举例，将你处理好的垂直数据与我给你的通用数据一起训练。分配的比例确保通用的数据量始终要更大一些。

然后，选择你打算训练的方式，如果你的数据量很大，例如可能都有几千万的token了，那我建议你选择full方式，也就是全参数微调。如果你只有大概几百、几十万、甚至更少的token量。那我建议你用lora的方式训练。训练的学习率选择5e5到2e5之间。数据集很多可以调高学习率，反之亦然。

llama-factor里面LoRA+学习率比例是一个很好用的参数，如果你发现模型的loss一直都降不下来，徘徊在2点几左右。可以去调高这里。推荐8或者16

当前的训练目标就是让模型拟合好你的数据。所以我们要做的就是将loss降下来。一般来说，loss降至0.7~1.4 之间就可以了。并不是越低越好。

只要到达了这个loss区间，加上用上了我给的通用数据集。基本上会有一个不错的效果。当然，限于篇幅原因。我说的这些训练内容在我看来还是比较的浅显。垂直模型训练也不会这么的简单。但对于我自己的多次实践。这种训练的方法。确实是一个最省力且有效果的方式。

其实想要分享的内容还有很多很多，例如真正的垂直模型是如何训练的？如何训练出一个完美模型？如何将系统性的学习和微调？后续模型如何一步步的优化和加强？还有我最新研究出来的实验内容等等。但是我打字打累了，这些内容也许得等到我下次再说。