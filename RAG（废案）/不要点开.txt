是的，这是一个RAG系统，实际上已经跑通了。但是效果并不好。可能是因为模型参数太小或者llama-factory太拉了。总之这是一个废弃的功能，并不打算放到正式介绍里面。
但是好不容易做的又不忍心仍了。所以就放在这里好了。

顺便再说几句，实际上llama-factory 我自己平时是不用的。因为我越发发现这个项目的训练算法好像不是很好。
我自己平时用的是这个镜像：https://www.codewithgpu.com/i/THUDM/GLM-4/ChatGLM4_glm4-9b
怎么说呢，同样的数据集和参数配置，训练出来的效果远远好于llama-factory 最直接的效果就是大大减轻了模型的过拟合效果。说实话我真的搞不懂是哪块代码不对。
可能还需要慢慢的研究。这也是我这么久都没更新llama-factory的原因之一了。
此外，我用的那个镜像不仅仅是微调效果好，它的各种函数调用 tool等等都是全方位的好。坏处就是只支持glm4系列的模型吧